{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrdL__lCtr6M"
   },
   "source": [
    "# ÐÐ½Ð½Ð° Ð—Ð°Ð¿Ð¾Ñ€Ð¾Ñ‰ÐµÐ½ÐºÐ¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_CzjN-StydR"
   },
   "source": [
    "Ð’ Ñ€Ð°Ð¼ÐºÐ°Ñ… ÑÑ‚Ð¾Ð³Ð¾ Ð·Ð°Ð´Ð°Ð½Ð¸Ñ Ð¼Ñ‹ Ð±ÑƒÐ´ÐµÐ¼ ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñƒ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð¿Ð¾Ð»ÑƒÑ‡Ð°Ñ Ð½Ð° Ð²Ñ…Ð¾Ð´ Ð¾Ñ‚Ð·Ñ‹Ð², Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ Ð¾Ñ‚Ð·Ñ‹Ð² Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ð¸Ð»Ð¸ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼. Ð”ÐµÐ»Ð°Ñ‚ÑŒ Ð¼Ñ‹ Ð±ÑƒÐ´ÐµÐ¼ ÑÑ‚Ð¾ Ñ‚Ð°ÐºÐ¸Ð¼ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð¼: Ð¼Ñ‹ Ð²Ð¾Ð·ÑŒÐ¼Ñ‘Ð¼ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ Ñ€Ð°Ð·Ð¼ÐµÑ‡ÐµÐ½Ð½Ñ‹Ñ… ÐºÐ°Ðº Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¸Ð»Ð¸ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð², Ð²Ñ‹Ð´ÐµÐ»Ð¸Ð¼ Ñ‚Ðµ ÑÐ»Ð¾Ð²Ð°, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÑŽÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¸Ð»Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ñ…, Ð¸ Ð±ÑƒÐ´ÐµÐ¼ ÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ, ÐºÐ°ÐºÐ¸Ñ… ÑÐ»Ð¾Ð²  Ð² Ð¿Ð¾ÑÑ‚ÑƒÐ¿Ð¸Ð²ÑˆÐµÐ¼ Ð½Ð°Ð¼ Ð½Ð° Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÑƒ Ð¾Ñ‚Ð·Ñ‹Ð²Ðµ Ð±Ð¾Ð»ÑŒÑˆÐµ.\n",
    "\n",
    "\n",
    "ÐœÑ‹ Ð±ÑƒÐ´ÐµÐ¼ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¿Ð¾ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ñ‘Ð½Ð½Ð¾Ð¼Ñƒ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ñƒ:\n",
    "\n",
    "1.  Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð½Ð°Ð¼ Ð½Ð°Ð´Ð¾ ÑÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð´Ð°Ñ‚Ñƒ -- ÑÐ¾Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÐºÐ°Ðº Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 60 (30 Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…  Ð¸ 30 Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…) Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð² Ð½Ð° Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ðµ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñ‹ (Ð½Ðµ Ð½Ð°Ð´Ð¾ Ð¼ÐµÑˆÐ°Ñ‚ÑŒ Ð¾Ñ‚Ð·Ñ‹Ð²Ñ‹ Ð½Ð° Ð¾Ñ‚ÐµÐ»Ð¸ Ñ Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ð¼Ð¸ Ð½Ð° Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐºÐ¸) Ð´Ð»Ñ ÑÐ¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ \" Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÑÐ»Ð¾Ð²Ð°Ñ€Ñ\" (Ñ‡ÐµÐ¼ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð², Ñ‚ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÐµ)  Ð¸ 10 Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð² Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°.   3 Ð±Ð°Ð»Ð»Ð° Ð² ÑÐ»ÑƒÑ‡Ð°Ðµ ÑÐ±Ð¾Ñ€Ð° Ð¿ÑƒÑ‚Ñ‘Ð¼ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°, 1 - ÐµÑÐ»Ð¸ Ð½Ð°Ð¹Ð´ÐµÑ‚Ðµ ÑƒÐ¶Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð·Ð°ÐºÐ¾Ð¿Ð¸Ð¿Ð°ÑÑ‚Ð¸Ñ‚Ðµ Ð±ÐµÐ· Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°\n",
    "\n",
    "2. Ð¢Ð¾ÐºÐµÐ½Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÑÐ»Ð¾Ð²Ð°,  Ð¿Ñ€Ð¸Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¸Ñ… Ðº Ð½Ð¸Ð¶Ð½ÐµÐ¼Ñƒ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ñƒ Ð¸ Ðº Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ðµ  (1 Ð±Ð°Ð»Ð» Ð·Ð° Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ†Ð¸ÑŽ, 1 - Ð·Ð° Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½ÑƒÑŽ Ñ„Ð¾Ñ€Ð¼Ñƒ)\n",
    "\n",
    "3. Ð¡Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ 2 Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð° - Ð² Ð¾Ð´Ð½Ð¾Ð¼ Ð±ÑƒÐ´ÑƒÑ‚ ÑÐ»Ð¾Ð²Ð°, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÑŽÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ñ…, Ð° Ð² Ð´Ñ€ÑƒÐ³Ð¾Ð¼ - Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÑŽÑ‰Ð¸ÐµÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð¸Ð³Ñ€Ð°Ñ‚ÑŒ Ñ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑÐ¼Ð¸ Ð¸ Ð¸ÑÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ ÑˆÑƒÐ¼ (Ðº Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñƒ, Ð²Ñ‹Ð±Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ ÑÐ»Ð¾Ð²Ð°, Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÑŽÑ‰Ð¸ÐµÑÑ 1-2 Ñ€Ð°Ð·Ð°) (3 Ð±Ð°Ð»Ð»Ð°) (ÐµÑÐ»Ð¸ Ñƒ Ð²Ð°Ñ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¸ÑÑŒ Ð¿ÑƒÑÑ‚Ñ‹Ðµ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð°, ÑƒÐ±ÐµÑ€Ð¸Ñ‚Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¸Ð»Ð¸ ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ)\n",
    "\n",
    "4. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÑ‚ÑŒ, Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð»Ð¸ Ð¾Ñ‚Ð·Ñ‹Ð² Ð¸Ð»Ð¸ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ‚Ð¾Ð³Ð¾, ÐºÐ°ÐºÐ¸Ðµ ÑÐ»Ð¾Ð²Ð° Ð²ÑÑ‚Ñ€ÐµÑ‚Ð¸Ð»Ð¸ÑÑŒ Ð² Ð½Ñ‘Ð¼, Ð¸ Ð¿Ð¾ÑÑ‡Ð¸Ñ‚Ð°Ð¹Ñ‚Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð¸ accuracy (1  - Ð·Ð° ÐºÐ¾Ñ€ÐµÐºÑ‚Ð½Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‰ÑƒÑŽ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ, 1 - Ð·Ð° Ð¿Ð¾Ð´ÑÑ‡Ñ‘Ñ‚ accuracy)\n",
    "\n",
    "5. ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ñ‚Ðµ ÐºÐ°Ðº Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 2 ÑÐ¿Ð¾ÑÐ¾Ð±Ð° ÑƒÐ»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ ÑÑ‚Ñƒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñƒ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ðº Ð½ÐµÐ¹ Ð»ÑŽÐ±Ñ‹Ñ… Ð¼ÑƒÐ»ÐµÐº  - Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸, Ð¿Ð¸ÑÐ°Ñ‚ÑŒ ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÑŽÑ‰Ð¸Ð¹ ÐºÐ¾Ð´ Ð½Ðµ Ð½Ð°Ð´Ð¾ (1 Ð±Ð°Ð»Ð»)\n",
    "\n",
    "6. Ð›Ð¾Ð³Ð¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¸ Ñ‡Ð¸ÑÑ‚Ð¾Ñ‚Ð° ÐºÐ¾Ð´Ð° (1 Ð±Ð°Ð»Ð») \n",
    "\n",
    "Ð”Ð°, Ñ‚ÑƒÑ‚ 12 Ð±Ð°Ð»Ð»Ð¾Ð² - Ð´Ð²Ð° Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾Ñ‚ÐµÑ€ÑÑ‚ÑŒ.\n",
    "\n",
    "\n",
    "Ð’ ÑÐ»ÑƒÑ‡Ð°Ðµ, ÐµÑÐ»Ð¸ Ð¿Ð¾ÑÐ»Ðµ Ð´Ð¾Ð»Ð³Ð¸Ñ… Ð¼ÑƒÑ‡ÐµÐ½Ð¸Ð¹ Ð² Ð¿. 3 Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð° Ð¿Ð¾ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¼ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð°Ð¼ Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ÑÑ (Ð¿Ð¾ÐºÐ°Ð¶Ð¸Ñ‚Ðµ, Ñ‡Ñ‚Ð¾ Ð¿Ñ‹Ñ‚Ð°Ð»Ð¸ÑÑŒ) - Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐ¹Ñ‚Ðµ Ð¶Ð°Ð±Ñƒ - Ð·Ð°Ñ‡ÑŒÑ‚Ñ‘Ð¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð±Ð°Ð»Ð»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "sMBivptux1xV",
    "outputId": "18135eb5-0550-49bb-bd26-865dfc2c744c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\VADIK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\VADIK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "igHuEg7R7Tyi"
   },
   "outputs": [],
   "source": [
    "#Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾Ñ‡Ð¸Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ñ‚ÐµÐºÑÑ‚Ð¾Ð² Ð¾Ñ‚ Ñ‚ÐµÐ³Ð¾Ð² Ð¸ Ð½ÐµÐ½ÑƒÐ¶Ð½Ñ‹Ñ… Ð·Ð½Ð°ÐºÐ¾Ð²\n",
    "def parse(info: list) -> list:\n",
    "    reviews = []\n",
    "    for i in info:\n",
    "        n = re.sub('<[A-Za-z\\/][^>]*>|\\r', '', i[1])\n",
    "        reviews.append(re.sub('\\n', '. ', n))\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "go-NP2ubgJek"
   },
   "outputs": [],
   "source": [
    "#Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°ÐµÑ‚ ÑÑÑ‹Ð»ÐºÑƒ Ð¸ Ð¸Ñ‰ÐµÑ‚ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð²ÑÐµ Ð¾Ñ‚Ð·Ñ‹Ð²Ñ‹ Ñ ÑÐ°Ð¼Ð¾Ð¹ Ð½Ð¸Ð·ÐºÐ¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¾Ð¹, Ð·Ð°Ñ‚ÐµÐ¼ - Ñ ÑÐ°Ð¼Ð¾Ð¹ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¹. \n",
    "#Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿Ð¾ 44 Ð¾Ñ‚Ð·Ñ‹Ð²Ð° ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð²Ð¸Ð´Ð° Ð¾Ð±Ñ‰Ð¸Ð¼ ÑÐ¿Ð¸ÑÐºÐ¾Ð¼.\n",
    "def get_reviews(url: str) -> list:\n",
    "    user_agent = UserAgent().chrome\n",
    "    req = urllib.request.Request(url, headers={'User-Agent':user_agent})\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        html_content = response.read().decode('utf-8')\n",
    "    bad_reviews = parse(re.findall('<b>1</b></span> Ð¸Ð· 10(.+?)jrReviewComment\"><div >(.+?)</div>', html_content, re.DOTALL))\n",
    "    good_reviews = parse(re.findall('<b>10</b></span> Ð¸Ð· 10(.+?)jrReviewComment\"><div >(.+?)</div>', html_content, re.DOTALL))\n",
    "    return bad_reviews[0:44] + good_reviews[0:44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð². ÐšÐ°Ð¶Ð´Ñ‹Ð¹ Ð¾Ñ‚Ð·Ñ‹Ð² Ð·Ð°Ð¼ÐµÐ½ÑÐµÑ‚ Ð½Ð° ÑÐ¿Ð¸ÑÐ¾Ðº Ð»ÐµÐ¼Ð¼, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÑ‚ \n",
    "#Ð¸Ð· Ð±ÑƒÐºÐ² Ð¸ Ð½Ðµ ÑÐ²Ð»ÑÑŽÑ‚ÑÑ ÑÑ‚Ð¾Ð¿-ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸. Ð’ÑÐµ ÑÐ»Ð¾Ð²Ð° Ð¿Ñ€Ð¸Ð²Ð¾Ð´ÑÑ‚ÑÑ Ðº Ð½Ð¸Ð¶Ð½ÐµÐ¼Ñƒ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ñƒ. Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ñƒ\n",
    "#ÑÐ¾ ÑÐ¿Ð¸ÑÐºÐ°Ð¼Ð¸ Ð»ÐµÐ¼Ð¼ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¾Ñ‚Ð·Ñ‹Ð²Ð°.\n",
    "#Ð’Ñ€ÑÐ´ Ð»Ð¸ ÑÑ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð½Ð° Google Colab, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ Mystem.lemmatize() Ð¿Ð¾Ð´Ð²Ð¸ÑÐ°ÐµÑ‚ Ð½Ð° Ð½ÐµÐ¼\n",
    "def preprocessing(reviews: list) -> list:\n",
    "    russian_stopwords = stopwords.words('russian')\n",
    "    m = Mystem()\n",
    "    reviews_new = []\n",
    "    for review in tqdm(reviews):\n",
    "        review_new = []\n",
    "        for word in m.lemmatize(review):\n",
    "            if (word.isalpha())and(word not in russian_stopwords):\n",
    "                review_new.append(word.lower())\n",
    "        reviews_new.append(review_new)\n",
    "    return reviews_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!NEW CODE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_2(reviews: list, token_reviews: list) -> list:\n",
    "    m = Mystem()\n",
    "    for r in tqdm(enumerate(reviews)):\n",
    "        doc = Doc(r[1])\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        doc.parse_syntax(syntax_parser)\n",
    "        heads = []\n",
    "        for token in doc.tokens:\n",
    "            if (token.pos == 'NOUN')or(token.pos == 'ADJ')or(token.pos == 'PREP'):\n",
    "                heads.append(token.id)\n",
    "        for head in heads:\n",
    "            collacation = ''\n",
    "            for token in doc.tokens:\n",
    "                if ((token.id == head)or(token.head_id == head))and(token.text.isalpha() == True):\n",
    "                    collacation += m.lemmatize(token.text.lower())[0] + ' '\n",
    "            if len(collacation.strip(' ').split(' ')) > 1:\n",
    "                token_reviews[r[0]].append(collacation.strip(' '))\n",
    "    return token_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error occurred during loading data. Trying to use cache server https://fake-useragent.herokuapp.com/browsers/0.1.11\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\urllib\\request.py\", line 1350, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\http\\client.py\", line 1240, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\http\\client.py\", line 1286, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\http\\client.py\", line 1235, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\http\\client.py\", line 1006, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\http\\client.py\", line 946, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\http\\client.py\", line 917, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\socket.py\", line 808, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\socket.py\", line 796, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\site-packages\\fake_useragent\\utils.py\", line 64, in get\n",
      "    with contextlib.closing(urlopen(\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\urllib\\request.py\", line 222, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\urllib\\request.py\", line 542, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\urllib\\request.py\", line 502, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\urllib\\request.py\", line 1379, in http_open\n",
      "    return self.do_open(http.client.HTTPConnection, req)\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\urllib\\request.py\", line 1353, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\site-packages\\fake_useragent\\utils.py\", line 164, in load\n",
      "    browsers_dict[browser_key] = get_browser_versions(\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\site-packages\\fake_useragent\\utils.py\", line 120, in get_browser_versions\n",
      "    html = get(\n",
      "  File \"C:\\Users\\VADIK\\anaconda3\\lib\\site-packages\\fake_useragent\\utils.py\", line 84, in get\n",
      "    raise FakeUserAgentError('Maximum amount of retries reached')\n",
      "fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached\n"
     ]
    }
   ],
   "source": [
    "reviews = get_reviews('https://www.megacritic.ru/film/prometej')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:42<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "token_reviews = preprocessing(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [2:05:01, 85.24s/it] \n"
     ]
    }
   ],
   "source": [
    "collacations_and_words = preprocessing_2(reviews, token_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!NEW CODE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "YmEW9qwWNbU3",
    "outputId": "1deebe5b-1baa-4213-e95a-b2e9dbc15e9e"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(collacations_and_words),\n",
    "                                                    np.concatenate((np.zeros(44), np.ones(44))),\n",
    "                                                    test_size=10/88,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ð¡Ð¿Ð¸ÑÐºÐ¸ Ð»ÐµÐ¼Ð¼ Ð¸Ð· Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¸ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð² X_train Ð¿Ð¾Ð¼ÐµÑ‰Ð°ÑŽÑ‚ÑÑ Ð² Ð´Ð²Ð° Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÐ¿Ð¸ÑÐºÐ°, \n",
    "#Ð¸Ð· Ð½Ð¸Ñ… Ð¿Ð¾Ñ‚Ð¾Ð¼ ÑÐ¾Ð·Ð´Ð°ÑŽÑ‚ÑÑ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°Ñ€Ð¸.Ð¢Ð°ÐºÐ¶Ðµ ÑÐ¾Ð·Ð´Ð°ÐµÑ‚ÑÑ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ñ‹Ð¹ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð¿Ð¾ Ð²ÑÐµÐ¼ Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ð¼ X_train.\n",
    "bad_reviews = []\n",
    "good_reviews = []\n",
    "for y in enumerate(y_train):\n",
    "    if y[1] == 0:\n",
    "        bad_reviews.extend(X_train[y[0]])\n",
    "    else:\n",
    "        good_reviews.extend(X_train[y[0]])\n",
    "bad_reviews = Counter(bad_reviews)\n",
    "good_reviews = Counter(good_reviews)\n",
    "reviews = Counter(sum(X_train.tolist(), []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°ÐµÑ‚ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°Ñ€Ð¸ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¸ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð², Ð° Ñ‚Ð°ÐºÐ¶Ðµ Ð¾Ð±Ñ‰Ð¸Ð¹ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ñ‹Ð¹ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ.\n",
    "#ÐžÐ½Ð° ÑÐ¾Ð·Ð´Ð°ÐµÑ‚ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ ÑÐ¾ ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ñ€Ð¸ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚ Ð¸ Ð² Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…, Ð¸ Ð² Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ñ….\n",
    "def check (bad_reviews: Counter, good_reviews: Counter, reviews: Counter) -> Counter:\n",
    "    words = Counter()\n",
    "    for word, value in reviews.items():\n",
    "        if (word in bad_reviews.keys())and(word in good_reviews.keys()):\n",
    "            words[word] = value\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ñ€ÐµÐ³ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ, Ð½Ð°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ‡Ð°ÑÑ‚Ð¾ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÑŽÑ‰Ð¸ÐµÑÑ ÑÐ»Ð¾Ð²Ð° Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ Ð² Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ check.\n",
    "def cutter (reviews: Counter, start: int, stop: int) -> Counter:\n",
    "    new_reviews = Counter()\n",
    "    for word, value in reviews.items():\n",
    "        if (value >= start)and(value <= stop):\n",
    "            new_reviews[word] = value\n",
    "    return new_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÐœÐ¾Ð¶Ð½Ð¾ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ, ÐµÑÑ‚ÑŒ Ð»Ð¸ ÐºÐ°ÐºÐ°Ñ-Ñ‚Ð¾ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ, Ð¿Ñ€Ð¸ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¹ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð°Ñ Ð»ÐµÐ¼Ð¼Ð° Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÐµÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ð¾Ð´Ð½Ð¾Ð¼ Ð²Ð¸Ð´Ðµ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð². Ð•Ð´Ð¸Ð½Ð¸Ñ†Ð° Ð½Ðµ Ð´Ð°ÐµÑ‚ Ð½Ð°Ð¼ ÐºÐ°ÐºÐ¾Ð¹-Ð»Ð¸Ð±Ð¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸, Ñ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒÑŽ 19 Ð½Ð° ÑÐ°Ð¼Ð¾Ð¼ Ð´ÐµÐ»Ðµ ÐµÑÑ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ 1 ÑÐ»Ð¾Ð²Ð¾."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  1  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  0\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  2  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  148\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  3  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  82\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  4  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  59\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  5  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  30\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  6  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  26\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  7  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  16\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  8  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  11\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  9  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  6\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  10  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  5\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  11  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  11\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  12  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  4\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  13  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  3\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  14  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  3\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  15  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  2\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  17  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  5\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  18  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  1\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  19  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  0\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  20  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  2\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  22  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  2\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  23  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  2\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  24  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  1\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  27  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  3\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  28  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  1\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  34  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  1\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  40  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  1\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  43  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  1\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  65  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  1\n",
      "Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð°  152  ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð²  1\n"
     ]
    }
   ],
   "source": [
    "numbers = list(Counter(reviews.values()).keys())\n",
    "numbers.sort()\n",
    "for number in numbers:\n",
    "    print('Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð²Ð° ', number, ' ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð² ', \n",
    "          len(check(bad_reviews, good_reviews, cutter(reviews, number, number))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð—Ð°Ñ‚Ð¾ Ð¼Ð¾Ð¶Ð½Ð¾ ÑƒÐ²Ð¸Ð´ÐµÑ‚ÑŒ, Ñ‡Ñ‚Ð¾ ÑÐ»Ð¾Ð²Ð° Ð¿ÐµÑ€ÐµÑÑ‚Ð°ÑŽÑ‚ ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð±Ð¾Ð»ÑŒÑˆÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ \"ÑˆÑƒÐ¼Ð°\", ÐºÐ¾Ð³Ð´Ð° Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÑŽÑ‚ÑÑ Ð±Ð¾Ð»ÐµÐµ 6 Ñ€Ð°Ð·. Ð Ð¾Ð²Ð½Ð¾ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÑŒ Ð²ÑÐµ ÑÐ»Ð¾Ð²Ð° Ð½Ð° \"Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ\" Ð¸ \"Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ\" Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = check(bad_reviews, good_reviews, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(neutral: Counter, polar: Counter) -> Counter:\n",
    "    new = Counter()\n",
    "    for word, value in polar.items():\n",
    "        if word not in neutral: #ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ ÑÐ»Ð¾Ð²Ð° Ñ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¼ÐµÐ½ÑŒÑˆÐµ 3\n",
    "            new[word] = value\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_reviews = get_words(neutral, bad_reviews)\n",
    "good_reviews = get_words(neutral, good_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ ÐºÐ°Ð¶Ð´Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¾Ñ‚Ð·Ñ‹Ð²Ðµ.\n",
    "#Ð•ÑÐ»Ð¸ ÑÐ»Ð¾Ð²Ð¾ ÐµÑÑ‚ÑŒ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€Ðµ Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð², score Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ -1, ÐµÑÐ»Ð¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€Ðµ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… - +1.\n",
    "#Ð¢Ð°ÐºÐ¸Ð¼ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð¼, ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð¾Ñ‚Ð·Ñ‹Ð² Ð½Ð°ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ ÑÐ²Ð¾Ð¹ score, Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ.\n",
    "def predict(X_test: np.array, bad_reviews: Counter, good_reviews: Counter) -> np.array:\n",
    "    results = []\n",
    "    for review in X_test:\n",
    "        score = 0\n",
    "        for word in review:\n",
    "            if word in bad_reviews.keys():\n",
    "                score -= 1\n",
    "            elif word in good_reviews.keys():\n",
    "                score +=1\n",
    "            else:\n",
    "                pass\n",
    "        if score < 0:\n",
    "            results.append(0)\n",
    "        else:\n",
    "            results.append(1)\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predict(X_test, bad_reviews, good_reviews), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÐÐ¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»Ð¾ÑÑŒ ðŸ˜­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ\n",
    "1) Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ n-Ð³Ñ€Ð°Ð¼Ð¼Ñ‹.\n",
    "2) \"ÐÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ðµ\" ÑÐ»Ð¾Ð²Ð° Ñ‚Ð¾Ð¶Ðµ Ð¼Ð¾Ð³Ð»Ð¸ Ð±Ñ‹ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¼Ð¸: ÐµÑÐ»Ð¸ ÑÐ»Ð¾Ð²Ð¾ Ð²ÑÑ‚Ñ€ÐµÑ‚Ð¸Ð»Ð¾ÑÑŒ 1 Ñ€Ð°Ð· Ð² Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ñ… Ð¸ 40 Ð² Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…, Ð¸ÑÐºÐ»ÑŽÑ‡Ð°Ñ‚ÑŒ ÐµÐ³Ð¾ Ð¿Ñ€Ð¸ ÑÑ‚Ð¾Ð¼ Ð¾Ð±ÑŠÐµÐ¼Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð½ÐµÐ²Ñ‹Ð³Ð¾Ð´Ð½Ð¾."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hometask 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
